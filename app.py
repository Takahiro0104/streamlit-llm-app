import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

import os
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# LLMè¨­å®šï¼ˆGPT-4o miniã‚’ä½¿ç”¨ï¼‰
llm = ChatOpenAI(openai_api_key=api_key, model_name="GPT-4o mini", temperature=0)

# â–¼ é–¢æ•°ï¼šå°‚é–€å®¶ã®ç¨®é¡ã¨å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€LLMã‹ã‚‰å›ç­”ã‚’å¾—ã‚‹
def generate_response(role: str, user_input: str) -> str:
    # å°‚é–€å®¶ã®å½¹å‰²ã«å¿œã˜ãŸSystemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    system_message = f"You are a helpful expert in the field of {role}."

    # ä¼šè©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    messages = [
        SystemMessage(content=system_message),
        HumanMessage(content=user_input)
    ]

    response = llm(messages)
    return response.content

# â–¼ Streamlit UIæ§‹æˆ
st.title("å°‚é–€å®¶LLMãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª ğŸ¤–ğŸ’¬")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ã•ã¾ã–ã¾ãªå°‚é–€å®¶ã«è³ªå•ã‚’ã—ã¦å›ç­”ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã§æ“ä½œã—ã¦ãã ã•ã„ï¼š")
st.markdown("""
1. å°‚é–€å®¶ã®åˆ†é‡ã‚’é¸æŠ
2. è³ªå•ã‚’å…¥åŠ›
3. ã€Œé€ä¿¡ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
""")

# å°‚é–€å®¶ã®ç¨®é¡ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ å¯èƒ½ï¼‰
expert_roles = ["å¥åº·", "æ³•å¾‹", "æ—…è¡Œ", "æ­´å²", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼"]
selected_role = st.radio("å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š", expert_roles)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›
user_question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")

# ãƒœã‚¿ãƒ³ã§é€ä¿¡å‡¦ç†
if st.button("é€ä¿¡"):
    if user_question.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å°‚é–€å®¶ãŒè€ƒãˆä¸­..."):
            answer = generate_response(selected_role, user_question)
            st.success("å›ç­”ï¼š")
            st.write(answer)